{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\programdata\\anaconda3\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (2.26.0)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (3.0.9)\n",
      "Requirement already satisfied: pandas>=1.2.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.4)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.5.1.221024)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.20.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.3->openai) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-stubs>=1.1.0.11->openai) (2022.6.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# Libraries Installation\n",
    "!pip install openai\n",
    "# Required Libraries\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nyio (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -latbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atbuffers (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export your API Key to environment variable\n",
    "# Upload the .env file to the directory \"/content/\"\n",
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set the API key for OpenAI\n",
    "openai.api_key = \"open_ai_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a class called RequirementProcessor\n",
    "class RequirementProcessor:\n",
    "    def __init__(self):\n",
    "        # During initialization, we set the model to a specific GPT model name.\n",
    "        self.model = \"gpt-3.5-turbo-16k\"\n",
    "\n",
    "    def process_requirement(self, requirement_description, system_prompt):\n",
    "        \"\"\"\n",
    "        Generates a response based on the given requirement description and system prompt using the OpenAI API.\n",
    "\n",
    "        Parameters:\n",
    "        - requirement_description (str): The description of the requirement.\n",
    "        - system_prompt (str): The initial system prompt for context.\n",
    "\n",
    "        Returns:\n",
    "        - str: The generated text based on the provided input.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a list of messages to send to the OpenAI API.\n",
    "        # The first message is from the system for context and the second is the user's requirement.\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": requirement_description},\n",
    "        ]\n",
    "\n",
    "        # Set the temperature (affects randomness of output) and maximum token limit for the response.\n",
    "        temperature = 1\n",
    "        max_tokens = 2000\n",
    "\n",
    "        # Call the OpenAI API's ChatCompletion method with the defined model and parameters.\n",
    "        response = openai.Completion.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "\n",
    "        # Extract and strip the generated content from the API response.\n",
    "        generated_text = response[\"choices\"][0].message[\"content\"].strip()\n",
    "\n",
    "        # Return the processed/generated text.\n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Analyse JD] Important descriptions for the job (Enter 'STOP' when you are done):\n",
      "[Analyse JD] Description uploaded\n"
     ]
    }
   ],
   "source": [
    "processor = RequirementProcessor()\n",
    "position_name = input(\"What is the name of the position? \")\n",
    "\n",
    "print(\"[Analyse JD] Important descriptions for the job (Enter 'STOP' when you are done):\")\n",
    "desc_content = []\n",
    "while True:\n",
    "    line = input()\n",
    "    if line.strip() == 'STOP' or line.strip() == 'stop':\n",
    "        break\n",
    "    desc_content.append(line)\n",
    "desc_content = '\\n'.join(desc_content)\n",
    "print(\"[Analyse JD] Description uploaded\")\n",
    "\n",
    "client_name = input(\"Name of the client: \")\n",
    "min_exp = input(\"Minimum experience in years: \")\n",
    "max_exp = input(\"Maximum experience in years: \")\n",
    "min_budget = input(\"Minimum salary budget (p.a): \")\n",
    "max_budget = input(\"Maximum salary budget (p.a): \")\n",
    "location_info = input(\"Location information: \")\n",
    "notice_period = input(\"Notice period: \")\n",
    "mandatory_skills = input(\"Enter the mandatory or must have skills for the job requirement: \")\n",
    "requirement_description = f'''Position name: {position_name}, description of the job and requirements: {desc_content}, Name of the client: {client_name}, \\\n",
    "Minimum experience required: {min_exp}, Maximum experience required: {max_exp}, Minimum budget for the salart p.a: {min_budget}, Maximum budget for the salart p.a: {max_budget}\\\n",
    "Location of the job: {location_info}, Notice period: {notice_period}, Mandatory or Must have skills required for this job: {mandatory_skills}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14344/4276736578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m '''\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mextracted_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_requirement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirement_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msystem_prompt_v1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"extracted information\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextracted_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14344/3267547845.py\u001b[0m in \u001b[0;36mprocess_requirement\u001b[1;34m(self, requirement_description, system_prompt)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# Call the OpenAI API's ChatCompletion method with the defined model and parameters.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         response = openai.Completion.create(\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    113\u001b[0m         )\n\u001b[0;32m    114\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         )\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             return (\n\u001b[1;32m--> 396\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    397\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                 ),\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"error\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    430\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "system_prompt_v1 = '''Give information about year of experience, CTC, notice period and educational requirement if available in the description. \\\n",
    "If not mark it as none. Also, summarize the technical skills needed.\\\n",
    "Summarize other needed skills like soft skills. \\\n",
    "Also, add must have skills - these are the most important requirements from the job description, clearly mentioned as must have skills. \\\n",
    "location is the place where the person will be posted. \\\n",
    "'''\n",
    "\n",
    "extracted_info = processor.process_requirement(requirement_description, system_prompt_v1)\n",
    "print(\"extracted information\", extracted_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_to_json(data, filename='data.json'):\n",
    "    \"\"\"\n",
    "    Save a Python data structure to a JSON file.\n",
    "\n",
    "    Args:\n",
    "    - data (dict or str): The Python data structure to be saved. Can be a string (that can be loaded as JSON) or a dictionary.\n",
    "    - filename (str): The name of the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Check if the data is already a string and try to load it into a Python object.\n",
    "    # If it's already a Python object (like a dictionary or list), then pass.\n",
    "    if isinstance(data, str):\n",
    "        try:\n",
    "            data = json.loads(data)\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(\"The provided string is not valid JSON.\")\n",
    "    elif not isinstance(data, (dict, list)):\n",
    "        raise TypeError(\"The data should either be a valid JSON string, dictionary, or list.\")\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "save_to_json(extracted_info, '/content/requirements_output.json')  # This will save the data to 'my_data.json' file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# https://drive.google.com/file/d/17V_o0Snt-Lj0FmegENPQ_rXpvWTWlZgQ/view?usp=sharing\n",
    "def download_file_from_google_drive(file_id, destination):\n",
    "    base_url = \"https://drive.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(base_url, params={'id': file_id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {'id': file_id, 'confirm': token}\n",
    "        response = session.get(base_url, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, destination)\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "# Example Usage\n",
    "# file_id = '1HaM3IeK2-iqyZzeQmCnAzKLcF9NF-mSo'  # Replace with your file's ID\n",
    "# destination = 'resume_data.zip'\n",
    "file_id = '17V_o0Snt-Lj0FmegENPQ_rXpvWTWlZgQ'\n",
    "destination = 'Webinar_resumes.zip'  # Replace with your desired file name and extension\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResumeProcessor:\n",
    "    def __init__(self):\n",
    "        self.resume_counter = 1\n",
    "    # Function to extract the CTC bounds from a given string in the format \"XX-YY\".\n",
    "    def get_ctc_bounds(self, ctc_range):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant to a recruiter. You will be given a range consisting of lower and upper salary amount in dollars. \\\n",
    "            Return the upper and lower values in dollars in expanded form. No currency should be mentioned. Output should be in JSON like {'lower':lower salary, 'upper': upper salary}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The salary range is {ctc_range}.\"},\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
    "        # print(\"iniital output\", generated_texts)\n",
    "\n",
    "        pattern = r'(\\d{1,3}(?:,\\d{3})*)\\s*(dollars)?'\n",
    "\n",
    "        matches = re.findall(pattern, generated_texts[0])\n",
    "        # print(\"matches\", matches)\n",
    "        if matches and len(matches) == 2:\n",
    "\n",
    "\n",
    "            # Extracting lower and upper salary from the matches and removing commas\n",
    "            try:\n",
    "              lower_salary = float(matches[0].replace(',', ''))\n",
    "              upper_salary = float(matches[1].replace(',', ''))\n",
    "            except:\n",
    "              lower_salary = float(matches[0][0].replace(',', ''))\n",
    "              upper_salary = float(matches[1][0].replace(',', ''))\n",
    "\n",
    "            return lower_salary, upper_salary\n",
    "        else:\n",
    "            return None\n",
    "        return generated_texts[0]\n",
    "\n",
    "    def convert_notice_period_to_days(self, jd_notice):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You're assisting a recruiter. Convert the provided notice period into days. \\\n",
    "            1 month is typically 30 days, and 1 year is 365 days. The final output should be 'Days': Number of days.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Given notice period: {jd_notice}. Return the output in json with the field 'Days'\"}\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
    "        # print(generated_texts, generated_texts[0])\n",
    "        return int(re.findall(r'\\d+', generated_texts[0])[0])\n",
    "    def extract_and_rename(self, zip_file_path):\n",
    "        # Specify the directory where the files will be extracted.\n",
    "        extract_path = \"extracted_files\"\n",
    "\n",
    "        # Open the zip file for reading.\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            # Extract all files/directories in the zip to the specified directory.\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "        # Start by assuming the path for the resumes is the extraction directory.\n",
    "        resume_path = extract_path\n",
    "\n",
    "        # Loop over each item (file or directory) in the extraction directory.\n",
    "        for item in os.listdir(extract_path):\n",
    "            # Construct the full path for the item.\n",
    "            item_path = os.path.join(extract_path, item)\n",
    "\n",
    "            # Check if the current item is a directory and if its name contains spaces.\n",
    "            if os.path.isdir(item_path) and ' ' in item:\n",
    "                # Replace spaces in the directory name with underscores.\n",
    "                new_name = item.replace(' ', '_')\n",
    "                # Construct the new path for the directory after renaming.\n",
    "                new_path = os.path.join(extract_path, new_name)\n",
    "\n",
    "                # If a directory with the new name doesn't already exist, create one.\n",
    "                if not os.path.exists(new_path):\n",
    "                    os.makedirs(new_path)\n",
    "\n",
    "                # Copy each file/sub-item from the old directory (with spaces in the name) to the new directory.\n",
    "                for sub_item in os.listdir(item_path):\n",
    "                    shutil.copy2(os.path.join(item_path, sub_item), new_path)\n",
    "\n",
    "                # Remove the old directory (with spaces in the name).\n",
    "                shutil.rmtree(item_path)\n",
    "                # Update the resume path to point to the new directory.\n",
    "                resume_path = new_path\n",
    "            else:\n",
    "                # If the item is not a directory (i.e., it's a file), update the resume path to point to this file.\n",
    "                resume_path = item_path\n",
    "\n",
    "        # Return the path where the resumes are located (either a directory or a single file).\n",
    "        return resume_path\n",
    "\n",
    "    def generate_random_data(self, upper_bound, lower_bound, total_resumes, max_notice_period_days):\n",
    "        # Define a list of Californian cities.\n",
    "        californian_cities = ['San Francisco', 'San Diego', 'Sacramento', 'Oakland']\n",
    "\n",
    "        # Modify thresholds to skew random generation towards more favorable candidates.\n",
    "        threshold_80_percent = 0.80 * total_resumes  # Increased from 50%\n",
    "        threshold_90_percent = 0.90 * total_resumes\n",
    "        threshold_10_percent = 0.10 * total_resumes  # Increased from 20%\n",
    "\n",
    "        # Skew CTC generation to be within the desired range for 80% of candidates.\n",
    "        if self.resume_counter < threshold_80_percent:\n",
    "            current_ctc = round(random.uniform(lower_bound, upper_bound), 1)\n",
    "            expected_ctc = round(random.uniform(current_ctc + 1, upper_bound), 1)\n",
    "        else:\n",
    "            current_ctc = round(random.uniform(0.5 * lower_bound, lower_bound - 1), 1)\n",
    "            expected_ctc = round(random.uniform(current_ctc + 1, upper_bound), 1)\n",
    "\n",
    "        # 90% candidates are willing to relocate.\n",
    "        if self.resume_counter < threshold_90_percent:\n",
    "            willing_to_relocate = \"yes\"\n",
    "        else:\n",
    "            willing_to_relocate = \"no\"\n",
    "\n",
    "        # Adjust notice period distribution.\n",
    "        if self.resume_counter < threshold_10_percent:\n",
    "            notice_period = f\"{random.randint(max_notice_period_days + 1, max_notice_period_days + 30)} days\"\n",
    "        else:\n",
    "          notice_period = f\"{random.randint(10, max_notice_period_days//2)} days\"\n",
    "\n",
    "        current_location = random.choice(californian_cities)\n",
    "        self.resume_counter += 1\n",
    "\n",
    "        return current_ctc, expected_ctc, willing_to_relocate, current_location, notice_period\n",
    "\n",
    "    def random_data_resumes(self, zip_file_path):\n",
    "        # Extract resumes from the zip file and rename them if necessary.\n",
    "        resume_path = self.extract_and_rename(zip_file_path)\n",
    "\n",
    "        # List out all the resume files present in the extracted path with specific extensions (.pdf, .doc, .docx).\n",
    "        resume_files = [f for f in os.listdir(resume_path) if f.endswith(('.pdf', '.doc', '.docx'))]\n",
    "        applications = []\n",
    "\n",
    "        # Read the job requirements from the \"requirements_output.json\" file.\n",
    "        with open(\"requirements_output.json\", \"r\") as f:\n",
    "            job_req = json.load(f)\n",
    "        # Convert the notice period (from job requirements) to days.\n",
    "        notice_period_criteria = self.convert_notice_period_to_days(job_req.get(\"notice_period\", \"\"))\n",
    "        # Get the lower and upper bounds of the CTC from the job requirements.\n",
    "        print(self.get_ctc_bounds(job_req.get(\"CTC\", \"\")))\n",
    "        lower_bound, upper_bound = self.get_ctc_bounds(job_req.get(\"CTC\", \"\"))\n",
    "\n",
    "        # Iterate over each resume file.\n",
    "        for filename in resume_files:\n",
    "            resume_file_path = os.path.join(resume_path, filename)\n",
    "            # Generate an email ID using the filename (assuming the file name does not contain periods other than the file extension).\n",
    "            email_id = filename.split('.')[0] + \"@example.com\"\n",
    "            # Generate random data for the current resume.\n",
    "            current_ctc, expected_ctc, willing_to_relocate, current_location, notice_period = self.generate_random_data(upper_bound, lower_bound, len(resume_files), notice_period_criteria)\n",
    "\n",
    "            # Append the generated data for the current resume to the applications list.\n",
    "            applications.append({\n",
    "                'current_ctc': current_ctc,\n",
    "                'expected_ctc': expected_ctc,\n",
    "                'willing_to_relocate': willing_to_relocate,\n",
    "                'current_location': current_location,\n",
    "                'notice_period': notice_period,\n",
    "                'email_id': email_id,\n",
    "                'resume_path': filename\n",
    "            })\n",
    "\n",
    "        # Save the entire applications list to a JSON file.\n",
    "        with open(\"all_applications.json\", \"w\") as f:\n",
    "            json.dump(applications, f, indent=4)\n",
    "\n",
    "# Using the class:\n",
    "processor = ResumeProcessor()\n",
    "processor.random_data_resumes(\"/content/Webinar_resumes.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing various formats for CTC:\n",
    "result = processor.get_ctc_bounds(\"100k-150k\")\n",
    "print(f\"Input '100k-150k', Output: {result} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing various formats for Notice period:\n",
    "result = processor.convert_notice_period_to_days(\"1 month\")\n",
    "print(f\"Input '1 month', Output: {result} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FilterCTC:\n",
    "    def __init__(self):\n",
    "        # Create an instance of the resume processor class\n",
    "        self.processor = ResumeProcessor()\n",
    "\n",
    "    def get_ctc_check(self, budget_min, budget_max, cr_ctc, exp_ctc):\n",
    "        \"\"\"\n",
    "        Check if the candidate's current and expected CTC are within the company's budget range.\n",
    "\n",
    "        :param budget_min: Minimum budget of the company for CTC\n",
    "        :param budget_max: Maximum budget of the company for CTC\n",
    "        :param cr_ctc: Candidate's current CTC\n",
    "        :param exp_ctc: Candidate's expected CTC\n",
    "\n",
    "        :return: True if candidate's CTC is within budget, else False\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant to a recruiter. You will be given the budget of the company (a range), candidate's current total compensation, and expected total compensation. \\\n",
    "            Return 'yes' if the current compensation is greater than the budget minimum and the expected total compensation is less than the maximum budget. Both conditions should be met for a 'yes'. For all other cases, return 'no'.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Company budget minimum: {budget_min}, company budget maximum: {budget_max}, candidate current total compensation: {cr_ctc}, candidate total expected compensation: {exp_ctc}\"},\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        result = response.choices[0].message[\"content\"].strip().lower()\n",
    "        return result == \"yes\"\n",
    "\n",
    "    def filter_CTC_resumes(self):\n",
    "        \"\"\"\n",
    "        Load resumes and job requirements, and filter out resumes based on CTC.\n",
    "        The filtered resumes are saved to 'filtered_applications_ctc.json' and the ones which didn't meet criteria to 'removed_resume_ctc.json'.\n",
    "        \"\"\"\n",
    "        # Load all applications from the JSON file\n",
    "        with open(\"all_applications.json\", \"r\") as f:\n",
    "            applications = json.load(f)\n",
    "\n",
    "        # Load job requirements from the JSON file\n",
    "        with open(\"requirements_output.json\", \"r\") as f:\n",
    "            job_req = json.load(f)\n",
    "\n",
    "        # Assume a method exists to get the CTC bounds from the job requirements\n",
    "        lower_bound, upper_bound = self.processor.get_ctc_bounds(job_req.get(\"CTC\", \"\"))\n",
    "\n",
    "        # Filter the applications based on the current and expected CTC criteria\n",
    "        filtered_applications_ctc = [app for app in applications if self.get_ctc_check(lower_bound, upper_bound, app['current_ctc'], app['expected_ctc'])]\n",
    "\n",
    "        # Identify the applications that were removed due to not meeting the CTC criteria\n",
    "        removed_due_to_ctc = [app for app in applications if app not in filtered_applications_ctc]\n",
    "\n",
    "        # Save the filtered applications to a new JSON file\n",
    "        with open(\"filtered_applications_ctc.json\", \"w\") as f:\n",
    "            json.dump(filtered_applications_ctc, f, indent=4)\n",
    "\n",
    "        # Save the applications that didn't meet the criteria to a separate JSON file\n",
    "        with open(\"removed_resume_ctc.json\", \"w\") as f:\n",
    "            json.dump(removed_due_to_ctc, f, indent=4)\n",
    "filterctc = FilterCTC()\n",
    "filterctc.filter_CTC_resumes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing various formats for CTC check:\n",
    "budget_min = \"100k\"\n",
    "budget_max = \"150k\"\n",
    "cr_ctc = \"120,000\"\n",
    "exp_ctc = \"140,000\"\n",
    "result = filterctc.get_ctc_check(budget_min, budget_max, cr_ctc, exp_ctc)\n",
    "print(f\"Input '{budget_min, budget_max, cr_ctc, exp_ctc}', Output: {result} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FilterCity:\n",
    "    # Initialize the object with job requirements and filtered ctc applications\n",
    "    def __init__(self, job_requirements_path, filtered_ctc_applications_path):\n",
    "        # Load the job requirements from the given file\n",
    "        with open(job_requirements_path, \"r\") as f:\n",
    "            self.job_req = json.load(f)\n",
    "\n",
    "        # Load the previously filtered applications from the given file\n",
    "        with open(filtered_ctc_applications_path, \"r\") as f:\n",
    "            self.filtered_applications_ctc = json.load(f)\n",
    "\n",
    "    def check_city(self, current_city, job_city, drive_hour = \"1-hour\"):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"You're assisting a recruiter. \\\n",
    "            Determine if the candidate's current city ({current_city}) and the prospective job city ({job_city})\\\n",
    "            are the same (even if the names vary or there may be spelling mistakes) then return 'yes'.\\\n",
    "            If both the cities {current_city} & {job_city} are within a {drive_hour} drive by car from each other, in that case you should \\\n",
    "            return 'yes', otherwise return 'no'.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Candidate's current city: {current_city}. Job's city: {job_city}.\"}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        generated_texts = [choice.message[\"content\"].strip() for choice in response[\"choices\"]]\n",
    "        return \"Yes\" in generated_texts or \"yes\" in generated_texts\n",
    "    # Filter applicants based on their willingness to relocate or if they are in the same city\n",
    "    def filter_by_willing_to_relocate_and_city(self):\n",
    "        filtered_applications = []\n",
    "        job_city = self.job_req.get(\"City\", \"\")\n",
    "\n",
    "        # Iterate through each application\n",
    "        for application in self.filtered_applications_ctc:\n",
    "            # If the 'willing_to_relocate' field is 'n.a.', set it to 'yes'\n",
    "            if application['willing_to_relocate'].lower() == \"n.a.\":\n",
    "                application['willing_to_relocate'] = 'yes'\n",
    "\n",
    "            # Check if the applicant's current location matches the job city\n",
    "            same_city = application['current_location'].lower() == job_city.lower()\n",
    "\n",
    "            # Check if the applicant is willing to relocate\n",
    "            willing_to_relocate = application['willing_to_relocate'].lower() == 'yes'\n",
    "\n",
    "            # If applicant is in the same city or willing to relocate, append to the filtered list\n",
    "            if same_city or willing_to_relocate:\n",
    "                filtered_applications.append(application)\n",
    "                continue\n",
    "            # If not in the same city and not willing to relocate, check willingness using the GPT model\n",
    "            if not same_city and not willing_to_relocate:\n",
    "                if self.check_city(application['current_location'], job_city):\n",
    "                    filtered_applications.append(application)\n",
    "\n",
    "        return filtered_applications\n",
    "\n",
    "    # Save the filtered and removed applications to separate files\n",
    "    def save_filtered_and_removed(self, filtered_applications):\n",
    "        # Find the applications that were removed due to city constraints\n",
    "        removed_due_to_city = [app for app in self.filtered_applications_ctc if app not in filtered_applications]\n",
    "\n",
    "        # Save the filtered applications\n",
    "        with open(\"filtered_applications_city.json\", \"w\") as f:\n",
    "            json.dump(filtered_applications, f, indent=4)\n",
    "\n",
    "        # Save the removed applications\n",
    "        with open(\"removed_due_to_city.json\", \"w\") as f:\n",
    "            json.dump(removed_due_to_city, f, indent=4)\n",
    "\n",
    "    # Process the filtering and saving operations\n",
    "    def process_filtering(self):\n",
    "        filtered_applications = self.filter_by_willing_to_relocate_and_city()\n",
    "        self.save_filtered_and_removed(filtered_applications)\n",
    "\n",
    "# Create an instance of the ApplicantFilter and process the applications\n",
    "applicant_filter = FilterCity(\"requirements_output.json\", \"filtered_applications_ctc.json\")\n",
    "applicant_filter.process_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our code with different variations:\n",
    "current_city = \"San Francisco\"\n",
    "job_city = \"san francisco\"\n",
    "drive_distnace = \"1-hour\"\n",
    "result = applicant_filter.check_city(current_city, job_city, drive_distnace)\n",
    "print(f\"Applicant location: {current_city}, Job locatoion: {job_city}, Drive distnace: {drive_distnace}\")\n",
    "print(f\"Result: {result} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FilterNotice:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize the ResumeFilter class with an instance of ResumeProcessor class\n",
    "        self.processor = ResumeProcessor()\n",
    "\n",
    "    def check_notice(self, jd_notice, can_notice):\n",
    "        \"\"\"\n",
    "        Convert notice periods given in months, years, or days to days, and check if the candidate's\n",
    "        notice period is less than or equal to the job's notice period.\n",
    "\n",
    "        :param jd_notice: Job's notice period\n",
    "        :param can_notice: Candidate's notice period\n",
    "\n",
    "        :return: 'yes' or 'no' indicating if the candidate's notice period is less than or equal to the job's notice period\n",
    "        \"\"\"\n",
    "        jd_notice = self.processor.convert_notice_period_to_days(jd_notice)\n",
    "        can_notice = self.processor.convert_notice_period_to_days(can_notice)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You're assisting a recruiter. Convert the provided notice periods into days. \\\n",
    "            1 month is typically 30 days, and 1 year is 365 days. If the candidate's notice period in days is less than the job's notice period in days, then return 'yes'. \\\n",
    "            Otherwise, reply 'no'. The output must be 'yes' or 'no'\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Job's notice period: {jd_notice}. Candidate's notice period: {can_notice}.\"}\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        generated_texts = [choice.message[\"content\"].strip().lower() for choice in response[\"choices\"]]\n",
    "        # print(\"initial output\", generated_texts, jd_notice, can_notice, \"jd_notice, can_notice\")\n",
    "        return generated_texts[0]\n",
    "\n",
    "    def filter_and_save(self):\n",
    "        # Load the job requirements\n",
    "        with open(\"requirements_output.json\", \"r\") as f:\n",
    "            job_req = json.load(f)\n",
    "\n",
    "        # Get the job's notice period criteria\n",
    "        notice_period_criteria = job_req.get(\"notice_period\", \"\")\n",
    "\n",
    "        # Load the previously filtered applications based on city\n",
    "        with open(\"filtered_applications_city.json\", \"r\") as f:\n",
    "            filtered_applications_city = json.load(f)\n",
    "\n",
    "        # Filter the previously filtered applications based on the notice period\n",
    "        filtered_applications_notice = [app for app in filtered_applications_city if self.check_notice(notice_period_criteria, app['notice_period']) == 'yes']\n",
    "        removed_due_to_notice = [app for app in filtered_applications_city if app not in filtered_applications_notice]\n",
    "\n",
    "        # Save the final filtered applications to a new JSON file\n",
    "        with open(\"filtered_applications.json\", \"w\") as f:\n",
    "            json.dump(filtered_applications_notice, f, indent=4)\n",
    "\n",
    "        # Save the resumes that were removed in the final filtering to another JSON file\n",
    "        with open(\"removed_resume_final.json\", \"w\") as f:\n",
    "            json.dump(removed_due_to_notice, f, indent=4)\n",
    "\n",
    "# Assuming the ResumeProcessor class is defined elsewhere, we create an instance of it\n",
    "\n",
    "filterer = FilterNotice()\n",
    "filterer.filter_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing various cases:\n",
    "notice_period_jd = \"One Month\"\n",
    "notice_period_candidate = \"29 days\"\n",
    "result = filterer.check_notice(notice_period_jd, notice_period_candidate)\n",
    "print(f\"Output for JD Notice period: {notice_period_jd} & Candidate notice period: {notice_period_candidate} is {result} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to count and return the number of entries in a given JSON file.\n",
    "def count_entries_in_json(json_filepath):\n",
    "    # Open and read the content of the JSON file.\n",
    "    with open(json_filepath, \"r\") as f:\n",
    "        data = json.load(f)  # Parse and load the JSON content into a variable.\n",
    "        return len(data)  # Return the number of top-level entries in the loaded data.\n",
    "\n",
    "# A list of file paths containing JSON data that we want to process.\n",
    "files = [\n",
    "    \"/content/all_applications.json\",\n",
    "    \"/content/filtered_applications.json\",\n",
    "    \"/content/removed_due_to_city.json\",\n",
    "    \"/content/removed_resume_ctc.json\",\n",
    "    \"/content/removed_resume_final.json\"\n",
    "]\n",
    "\n",
    "# Loop through each file in the list, count its entries, and print the result.\n",
    "for file in files:\n",
    "    count = count_entries_in_json(file)  # Use the function to count entries for the current file.\n",
    "    print(f\"{file}: {count} entries\")  # Display the file path along with its count of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# List of file paths that you want to download\n",
    "file_paths = [\n",
    "    \"/content/filtered_applications.json\",\n",
    "    \"/content/all_applications.json\"\n",
    "\n",
    "]\n",
    "\n",
    "# Download each file to your local system\n",
    "for path in file_paths:\n",
    "    files.download(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initial_score(text, prompt):\n",
    "    \"\"\"\n",
    "    Use OpenAI's model to generate a response based on the given prompt and text.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The content to be processed.\n",
    "    - prompt (str): The instruction or question for the model to guide its response.\n",
    "\n",
    "    Returns:\n",
    "    - str: Model-generated text based on the input text and prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    # Specify the model and token limits\n",
    "    model = \"gpt-3.5-turbo-16k\"\n",
    "    max_tokens = 2000\n",
    "\n",
    "    # Create a list of messages to simulate a conversation with the model.\n",
    "    # The system starts with a prompt, and the user provides the input text.\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"{prompt}\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "\n",
    "    # Make a request to the OpenAI API for the generated response.\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=1,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "\n",
    "    # Extract the generated text from the model's response\n",
    "    generated_texts = [\n",
    "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
    "    ]\n",
    "\n",
    "    return generated_texts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def user_select_number_of_resumes(total_resumes, default=2):\n",
    "    \"\"\"\n",
    "    Allow the user to input a number of resumes to process.\n",
    "    If no input is given, the default value is returned.\n",
    "\n",
    "    Args:\n",
    "    - total_resumes (int): Total number of resumes available.\n",
    "    - default (int): The default number to return if no input.\n",
    "\n",
    "    Returns:\n",
    "    - int: The number of resumes the user wants to process.\n",
    "    \"\"\"\n",
    "    print(f\"Total resumes available: {total_resumes}\")\n",
    "    user_input = input(f\"How many resumes do you want to process? (Default is {default}): \")\n",
    "\n",
    "    # If the user doesn't provide any input, return the default value.\n",
    "    if not user_input:\n",
    "        return default\n",
    "\n",
    "    try:\n",
    "        # Convert user input to an integer and ensure it's within the range.\n",
    "        selected_num = int(user_input)\n",
    "        if 1 <= selected_num <= total_resumes:\n",
    "            return selected_num\n",
    "        else:\n",
    "            print(f\"Please select a number between 1 and {total_resumes}.\")\n",
    "            return user_select_number_of_resumes(total_resumes, default)\n",
    "    except ValueError:\n",
    "        # If the user provides non-numeric input, prompt them again.\n",
    "        print(\"Please enter a valid number.\")\n",
    "        return user_select_number_of_resumes(total_resumes, default)\n",
    "\n",
    "# Read the filtered_applications_summary data from the JSON file\n",
    "json_data = read_json('/content/filtered_applications_summary.json')\n",
    "\n",
    "# Display total resumes and get the user's choice\n",
    "n = user_select_number_of_resumes(len(json_data))\n",
    "\n",
    "# Randomly select n resumes\n",
    "selected_applications = random.sample(json_data, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_version_1 = f'''You are an assistant to a recruiter. Your job is to evaluate a resume for a particular skill. The skills for which you need to do\n",
    "evaluation are {must_have_skills}. You need to find the projects in which a particular skill from this list has been applied.'''\n",
    "\n",
    "for application in selected_applications:\n",
    "    if 'resume_path' in application and 'email_id' in application:\n",
    "\n",
    "        # Extract resume text\n",
    "        resume_text = read_document(os.path.join(resume_path, application['resume_path']))\n",
    "        resume_text, _, _ = check_and_trim(resume_text)\n",
    "\n",
    "        # Directly assign the resume_summary without json.loads()\n",
    "        resume_summary = application['resume_summary']\n",
    "\n",
    "        # Score the resume against job requirements\n",
    "        initial_score_output = initial_score(resume_text, prompt_version_1)\n",
    "\n",
    "        print(f'''[Matching Request] for {resume_summary[\"name_of_candidate\"]} ''', initial_score_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_gen(must_have):\n",
    "    model=\"gpt-3.5-turbo-16k\"\n",
    "    max_tokens=4000\n",
    "    prompt_v1 = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
    "    Let's think step by step on how to look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
    "    As an example, take the case where the must have skills are \"SKILL1, SKILL2, SKILL3, SKILL4, SKILL5\". \\\n",
    "    Now generate a criterion to score each of the skill between 0 and 5.'''\n",
    "\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"{prompt_v1}\"},\n",
    "        ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "    generated_texts = [\n",
    "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
    "    ]\n",
    "    return generated_texts[0]\n",
    "\n",
    "\n",
    "\n",
    "criterion_gen_output = criterion_gen(must_have_skills)\n",
    "print(f'''[Criterion Generation Request] ''', criterion_gen_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_match = \"\"\"\n",
    "skill1:\n",
    "No projects: 0\n",
    "1 project or mention: one or two\n",
    "2 or 3 projects or mentions: three or four\n",
    "more than or equal to five projects or mentions: five\n",
    "\"\"\"\n",
    "def criterion_gen(must_have):\n",
    "    model=\"gpt-3.5-turbo-16k\"\n",
    "    max_tokens=4000\n",
    "    prompt_v2 = f'''I have a resume. I want to find a person whose resume has skills in {must_have}. \\\n",
    "    Let's think step by step on how to look into a resume and give score based on each of the skill mentioned in {must_have}. \\\n",
    "    As an example, take the case where the must have skills are \"SKILL1, SKILL2, SKILL3, SKILL4, SKILL5\". Now score each of the skill between 0 and 5.\\\n",
    "    For example use the criterion given in {string_match}'''\n",
    "\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"{prompt_v2}\"},\n",
    "        ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "    generated_texts = [\n",
    "        choice.message[\"content\"].strip() for choice in response[\"choices\"]\n",
    "    ]\n",
    "    return generated_texts[0]\n",
    "\n",
    "criterion_gen_output = criterion_gen(must_have_skills)\n",
    "print(f'''[Criterion Generation Request] ''', criterion_gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_score_func(resume_text, must_have_skills):\n",
    "    # Read the criteria and string_match from the text file\n",
    "    criterion_gen_output, string_match = read_from_textfile(\"/content/criterion_and_string_match_output.txt\")\n",
    "    prompt=f'''You are an assistant to a recruiter. \\\n",
    "    Use the criteria given by {criterion_gen_output} to judge the resume given to you and give score to \\\n",
    "    each of the skills present in {must_have_skills}.'''\n",
    "\n",
    "    # Assuming the function score_from_criterion exists and takes these parameters\n",
    "    score_output = score_from_criterion(prompt, resume_text, criterion_gen_output, must_have_skills, string_match)\n",
    "\n",
    "    return score_output\n",
    "\n",
    "for application in selected_applications:\n",
    "    if 'resume_path' in application and 'email_id' in application:\n",
    "\n",
    "        # Extract resume text\n",
    "        resume_text = read_document(os.path.join(resume_path, application['resume_path']))\n",
    "        resume_text, _, _ = check_and_trim(resume_text)\n",
    "\n",
    "        # Directly assign the resume_summary without json.loads()\n",
    "        resume_summary = application['resume_summary']\n",
    "\n",
    "        final_score_out = final_score_func(resume_text, must_have_skills)\n",
    "        print(f'''[Score Request] for {resume_summary[\"name_of_candidate\"]} ''', final_score_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
